{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "jPEhK4-n3Ekd",
      "metadata": {
        "id": "jPEhK4-n3Ekd"
      },
      "source": [
        "# References used for dataset <br>\n",
        "1. http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
        "2. https://github.com/seshuad/IMagenet"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eD-H5_Mn3Evm",
      "metadata": {
        "id": "eD-H5_Mn3Evm"
      },
      "source": [
        "# References used for network architecture\n",
        "1. https://arxiv.org/abs/1704.06904\n",
        "2. https://github.com/tengshaofeng/ResidualAttentionNetwork-pytorch/blob/master/Residual-Attention-Network/model/attention_module.py\n",
        "3. https://github.com/Piyushdharkar/Residual-Attention-Aware-Network\n",
        "4. https://github.com/deontaepharr/Residual-Attention-Network"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VXKai3jc3E0S",
      "metadata": {
        "id": "VXKai3jc3E0S"
      },
      "source": [
        "# References used for keras functions\n",
        "1. https://www.pyimagesearch.com/2019/07/22/keras-learning-rate-schedules-and-decay/\n",
        "https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html \n",
        "2. https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Sh-pQFe1_jlv",
      "metadata": {
        "id": "Sh-pQFe1_jlv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UKlrhzef_jlw",
      "metadata": {
        "id": "UKlrhzef_jlw"
      },
      "source": [
        "**Load the tiny ImageNet Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Bmg6SdDf_yPI",
      "metadata": {
        "id": "Bmg6SdDf_yPI"
      },
      "outputs": [],
      "source": [
        "! git clone https://github.com/seshuad/IMagenet\n",
        "! ls 'IMagenet/tiny-imagenet-200/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "v6dTU4HuFf8a",
      "metadata": {
        "id": "v6dTU4HuFf8a"
      },
      "outputs": [],
      "source": [
        "!pip install scipy==1.1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EJDzg6vJF74N",
      "metadata": {
        "colab": {
          "base_uri": "https://8080-cs-398499538725-default.cs-us-east1-vpcf.cloudshell.dev/",
          "height": 35
        },
        "id": "EJDzg6vJF74N",
        "outputId": "867460bb-6ddd-4ee2-a8be-09f0fb5af998"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'1.1.0'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import scipy\n",
        "scipy.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GhEYKl7n_0qJ",
      "metadata": {
        "colab": {
          "base_uri": "https://8080-cs-398499538725-default.cs-us-east1-vpcf.cloudshell.dev/"
        },
        "id": "GhEYKl7n_0qJ",
        "outputId": "58cae82e-5895-475f-a5a5-81bb6035763d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "starting loading data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:30: DeprecationWarning: `imread` is deprecated!\n",
            "`imread` is deprecated in SciPy 1.0.0.\n",
            "Use ``matplotlib.pyplot.imread`` instead.\n",
            "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `imread` is deprecated!\n",
            "`imread` is deprecated in SciPy 1.0.0.\n",
            "Use ``matplotlib.pyplot.imread`` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "finished loading data, in 77.47798323631287 seconds\n",
            "train data shape:  (100000, 64, 64, 3)\n",
            "train label shape:  (100000, 200)\n",
            "test data shape:  (10000, 64, 64, 3)\n",
            "test_labels.shape:  (10000, 200)\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import scipy.ndimage as nd\n",
        "import numpy as np\n",
        "\n",
        "path = 'IMagenet/tiny-imagenet-200/'\n",
        "\n",
        "def get_id_dictionary():\n",
        "    id_dict = {}\n",
        "    for i, line in enumerate(open( path + 'wnids.txt', 'r')):\n",
        "        id_dict[line.replace('\\n', '')] = i\n",
        "    return id_dict\n",
        "  \n",
        "def get_class_to_id_dict():\n",
        "    id_dict = get_id_dictionary()\n",
        "    all_classes = {}\n",
        "    result = {}\n",
        "    for i, line in enumerate(open( path + 'words.txt', 'r')):\n",
        "        n_id, word = line.split('\\t')[:2]\n",
        "        all_classes[n_id] = word\n",
        "    for key, value in id_dict.items():\n",
        "        result[value] = (key, all_classes[key])      \n",
        "    return result\n",
        "\n",
        "def get_data(id_dict):\n",
        "    print('starting loading data')\n",
        "    train_data, test_data = [], []\n",
        "    train_labels, test_labels = [], []\n",
        "    t = time.time()\n",
        "    for key, value in id_dict.items():\n",
        "        train_data += [nd.imread( path + 'train/{}/images/{}_{}.JPEG'.format(key, key, str(i)), mode='RGB') for i in range(500)]\n",
        "        train_labels_ = np.array([[0]*200]*500)\n",
        "        train_labels_[:, value] = 1\n",
        "        train_labels += train_labels_.tolist()\n",
        "\n",
        "    for line in open( path + 'val/val_annotations.txt'):\n",
        "        img_name, class_id = line.split('\\t')[:2]\n",
        "        test_data.append(nd.imread( path + 'val/images/{}'.format(img_name) ,mode='RGB'))\n",
        "        test_labels_ = np.array([[0]*200])\n",
        "        test_labels_[0, id_dict[class_id]] = 1\n",
        "        test_labels += test_labels_.tolist()\n",
        "\n",
        "    print('finished loading data, in {} seconds'.format(time.time() - t))\n",
        "    return np.array(train_data), np.array(train_labels), np.array(test_data), np.array(test_labels)\n",
        "  \n",
        "train_data, train_labels, test_data, test_labels = get_data(get_id_dictionary())\n",
        "\n",
        "print( \"train data shape: \",  train_data.shape )\n",
        "print( \"train label shape: \", train_labels.shape )\n",
        "print( \"test data shape: \",   test_data.shape )\n",
        "print( \"test_labels.shape: \", test_labels.shape )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9xZxkioM_jlx",
      "metadata": {
        "id": "9xZxkioM_jlx"
      },
      "outputs": [],
      "source": [
        "x_train = train_data\n",
        "y_train = train_labels\n",
        "x_test = test_data\n",
        "y_test = test_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3IbvDT1t_jlx",
      "metadata": {
        "colab": {
          "base_uri": "https://8080-cs-398499538725-default.cs-us-east1-vpcf.cloudshell.dev/"
        },
        "id": "3IbvDT1t_jlx",
        "outputId": "ebb5257f-1477-4c98-9d28-c5fad343c716"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " x_train.shape:  (100000, 64, 64, 3)\n",
            "\n",
            " y_train.shape:  (100000, 200)\n",
            "\n",
            " x_test.shape:  (10000, 64, 64, 3)\n",
            "\n",
            " y_test.shape:  (10000, 200)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n x_train.shape: \", x_train.shape)\n",
        "print(\"\\n y_train.shape: \", y_train.shape)\n",
        "\n",
        "print(\"\\n x_test.shape: \", x_test.shape)\n",
        "print(\"\\n y_test.shape: \", y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fRkizbbX_jly",
      "metadata": {
        "id": "fRkizbbX_jly"
      },
      "source": [
        "**Visualize the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "A5vAGwaO_jly",
      "metadata": {
        "id": "A5vAGwaO_jly"
      },
      "outputs": [],
      "source": [
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes = 200)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes = 200)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-y0Dkoxt_jly",
      "metadata": {
        "id": "-y0Dkoxt_jly"
      },
      "source": [
        "**Divide the data into train, test and validation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "APxl4dQn_jly",
      "metadata": {
        "id": "APxl4dQn_jly"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ch-PCKG_jlz",
      "metadata": {
        "id": "2ch-PCKG_jlz",
        "outputId": "97292f9a-0f3c-47a1-a876-adfaacded45d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " x_train.shape:  (80000, 64, 64, 3)\n",
            "\n",
            " y_train.shape:  (80000, 200)\n",
            "\n",
            " x_val.shape:  (20000, 64, 64, 3)\n",
            "\n",
            " y_val.shape:  (20000, 200)\n",
            "\n",
            " x_test.shape:  (10000, 64, 64, 3)\n",
            "\n",
            " y_test.shape:  (10000, 200)\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(0)\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, train_size = 0.8)\n",
        "\n",
        "print(\"\\n x_train.shape: \", x_train.shape)\n",
        "print(\"\\n y_train.shape: \", y_train.shape)\n",
        "\n",
        "print(\"\\n x_val.shape: \", x_val.shape)\n",
        "print(\"\\n y_val.shape: \", y_val.shape)\n",
        "\n",
        "print(\"\\n x_test.shape: \", x_test.shape)\n",
        "print(\"\\n y_test.shape: \", y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xBls6PAC_jlz",
      "metadata": {
        "id": "xBls6PAC_jlz"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "L7PE-ny9_jlz",
      "metadata": {
        "id": "L7PE-ny9_jlz"
      },
      "source": [
        "**Creating Residual Block**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pITXljmc_jlz",
      "metadata": {
        "id": "pITXljmc_jlz"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zuSGfsPO_jlz",
      "metadata": {
        "id": "zuSGfsPO_jlz"
      },
      "outputs": [],
      "source": [
        "def create_residual_block(val_in, filter_in, filter_out):\n",
        "    '''\n",
        "    @params val_in : Input shape\n",
        "    @params filter_in : Input filter\n",
        "    @params filter_out : Output filter\n",
        "    @output : Tensor created after residual block\n",
        "    '''\n",
        "    \n",
        "    # Repeat BN=>ReLU=>Conv2D pattern three times\n",
        "    \n",
        "    x = tf.keras.layers.BatchNormalization()(val_in)\n",
        "    x = tf.keras.activations.relu(x)\n",
        "    x = tf.keras.layers.Conv2D(filters = filter_in, kernel_size = 1, padding = 'same')(x)\n",
        "    \n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.activations.relu(x)\n",
        "    x = tf.keras.layers.Conv2D(filters = filter_out, kernel_size = 3, padding = 'same')(x)\n",
        "    \n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.activations.relu(x)\n",
        "    x = tf.keras.layers.Conv2D(filters = filter_out, kernel_size = 1, padding = 'same')(x)\n",
        "    \n",
        "    val_in = tf.keras.layers.Conv2D(filters = filter_out, kernel_size = 1, padding = 'same')(val_in)\n",
        "    \n",
        "    x = tf.keras.layers.Add()([val_in, x])\n",
        "    \n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QDAsh0Gx_jlz",
      "metadata": {
        "id": "QDAsh0Gx_jlz"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "orRbmdTg_jlz",
      "metadata": {
        "id": "orRbmdTg_jlz"
      },
      "source": [
        "**Creating Attention Block**\n",
        "\n",
        "The attention Module consists of mask branch and trunk branch. The trunk branch performs feature selection (using the residual blocks) and the mask branch learns the mask to be applied from downsampling and upsampling. The output of the attention block is (1+M(x)).T(x), where M(x) is the mask and T(x) is the output of the trunk branch (pre-processing)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hyiKrejm_jl0",
      "metadata": {
        "id": "hyiKrejm_jl0"
      },
      "outputs": [],
      "source": [
        "def create_attention_block(val_in, filter_in, filter_out, p = 1, t = 2, r = 1):\n",
        "    '''\n",
        "    @params val_in : Input shape\n",
        "    @params filter_in : Input filter\n",
        "    @params filter_out : Output filter\n",
        "    @params p : Number of pre-processing residual units before splitting into trunk and mask branch (is also a hyperparameter)\n",
        "    @params t : Number of residual units in trunk branch (is also a hyperparameter)\n",
        "    @params r : Number of residual units between adjacent pooling layer in the mask branch (is also a hyperparameter)\n",
        "    @output: Tensor created after attention block\n",
        "    '''\n",
        "    \n",
        "    # Creating residual blocks for pre-processing residual units\n",
        "    for units in range(p):\n",
        "        val_in = create_residual_block(val_in, filter_in, filter_out)\n",
        "     \n",
        "    val_out_trunk = val_in\n",
        "    \n",
        "    # Feature Processing for the trunk branch. Input to the trunk branch is the output of the pre-processing residual blocks\n",
        "    for units in range(t):\n",
        "        val_out_trunk = create_residual_block(val_out_trunk, filter_in, filter_out)\n",
        "        \n",
        "    # 1. Downsample using MaxPool2D\n",
        "    # 2. 'r' represents the number of residual units between two max pool layers in the mask branch. Implemented using for loop\n",
        "    # 3. Add skip connection\n",
        "    # 4. Upsample using UpSampling2D\n",
        "    \n",
        "    \n",
        "    # Down Sampling One\n",
        "    soft_mask_output = tf.keras.layers.MaxPool2D(pool_size = 2, padding = 'same')(val_in)\n",
        "    for units in range(r):\n",
        "        soft_mask_output = create_residual_block(soft_mask_output, filter_in, filter_out)\n",
        "    \n",
        "    \n",
        "    # Adding Skip Connection\n",
        "    skip_connection = create_residual_block(soft_mask_output, filter_in, filter_out)\n",
        "    \n",
        "    # Down Sampling Two\n",
        "    soft_mask_output = tf.keras.layers.MaxPool2D(pool_size = 2, padding = 'same')(soft_mask_output)\n",
        "    for units in range(r):\n",
        "        soft_mask_output = create_residual_block(soft_mask_output, filter_in, filter_out)\n",
        "    \n",
        "    # Up Sampling One\n",
        "    for units in range(r):\n",
        "        soft_mask_output = create_residual_block(soft_mask_output, filter_in, filter_out)\n",
        "        soft_mask_output = tf.keras.layers.UpSampling2D(size=2)(soft_mask_output)\n",
        "        soft_mask_output = tf.keras.layers.Add()([soft_mask_output, skip_connection])\n",
        "        \n",
        "    # Up Sampling Two\n",
        "    for units in range(r):\n",
        "        soft_mask_output = create_residual_block(soft_mask_output, filter_in, filter_out)\n",
        "    soft_mask_output = tf.keras.layers.UpSampling2D(size=2)(soft_mask_output)\n",
        "    \n",
        "    soft_mask_output = tf.keras.layers.Conv2D(filter_in, kernel_size=1)(soft_mask_output)\n",
        "    soft_mask_output = tf.keras.layers.Conv2D(filter_in, kernel_size=1)(soft_mask_output)\n",
        "    soft_mask_output = tf.keras.layers.Activation(activation='sigmoid')(soft_mask_output)\n",
        "    \n",
        "    # Output is (1 + M(x))*T(x)\n",
        "    output = tf.keras.layers.Lambda(lambda x: x + 1)(soft_mask_output)\n",
        "    output = tf.keras.layers.Multiply()([output, val_out_trunk]) \n",
        "    \n",
        "    for i in range(p):\n",
        "        output = create_residual_block(output, filter_in, filter_out)\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dMJkj0mJ_jl0",
      "metadata": {
        "id": "dMJkj0mJ_jl0"
      },
      "source": [
        "**Creating the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B_SZ4kIB_jl1",
      "metadata": {
        "id": "B_SZ4kIB_jl1"
      },
      "outputs": [],
      "source": [
        "def create_model(size, classes):\n",
        "    '''\n",
        "    @params size : Input tensor siz\n",
        "    @params classes : Number of output classes\n",
        "    @output : Returns the model created by attention modules\n",
        "    '''\n",
        "    val_in = tf.keras.layers.Input(shape=size)\n",
        "    x = tf.keras.layers.Conv2D(filters=32, kernel_size=5, strides=1, padding='same')(val_in)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation(activation='relu')(x)\n",
        "    x = tf.keras.layers.MaxPooling2D(pool_size=2, strides=1, padding='same')(x)\n",
        "\n",
        "    x = create_residual_block(val_in=x, filter_in=32, filter_out=128)\n",
        "    x = create_attention_block(val_in=x, filter_in=32, filter_out=32)\n",
        "\n",
        "    x = create_residual_block(val_in=x, filter_in=64, filter_out=128)\n",
        "    x = create_attention_block(val_in=x, filter_in=64, filter_out=64)\n",
        "\n",
        "    x = create_residual_block(val_in=x, filter_in=128, filter_out=256)\n",
        "    x = create_attention_block(val_in=x, filter_in=128, filter_out=128)\n",
        "\n",
        "    x = create_residual_block(val_in=x, filter_in=128, filter_out=256)\n",
        "    x = create_residual_block(val_in=x, filter_in=256, filter_out=256)\n",
        "    x = create_residual_block(val_in=x, filter_in=256, filter_out=256)\n",
        "\n",
        "    x = tf.keras.layers.AveragePooling2D(pool_size=4)(x)\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "    output = tf.keras.layers.Dense(classes, activation='softmax')(x)\n",
        "\n",
        "\n",
        "    return tf.keras.models.Model(val_in, output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6rfcBFI_jl1",
      "metadata": {
        "id": "a6rfcBFI_jl1"
      },
      "source": [
        "**Initialize the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RarO4cJX_jl1",
      "metadata": {
        "id": "RarO4cJX_jl1",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "model_imagenet = create_model(x_train.shape[1:], 200)\n",
        "\n",
        "model_imagenet.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sP5rzxBa_jl1",
      "metadata": {
        "id": "sP5rzxBa_jl1"
      },
      "source": [
        "**Viusalize the Model**\n",
        "\n",
        "To visualize the model, we use the Netron Package\n",
        "\n",
        "1. Install netron using the pip command below\n",
        "\n",
        "2. Download Netron package from here : https://github.com/lutzroeder/netron/releases/tag/v5.4.3\n",
        "\n",
        "3. Save the model using the command below\n",
        "\n",
        "4. Open and visualize the saved model with Netron"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Wvfrr1iw_jl2",
      "metadata": {
        "id": "Wvfrr1iw_jl2"
      },
      "source": [
        "**Train the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6vtNCPLx_jl2",
      "metadata": {
        "id": "6vtNCPLx_jl2"
      },
      "outputs": [],
      "source": [
        "def lr_schedule (epoch, lr):\n",
        "    if epoch == 100:\n",
        "        lr = 0.1 * lr\n",
        "        print(\"\\n Reducing learning by factor of 10 at epoch: \", epoch)\n",
        "    elif epoch == 150:\n",
        "        lr = 0.1 * lr\n",
        "        print(\"\\n Reducing learning by factor of 10 at epoch: \", epoch)\n",
        "    \n",
        "    return lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3lBaRLvx_jl2",
      "metadata": {
        "id": "3lBaRLvx_jl2"
      },
      "outputs": [],
      "source": [
        "augmented_data_train = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, validation_split=0.2, vertical_flip=True, \n",
        "                                                           rotation_range=0.15, width_shift_range=0.15, height_shift_range=0.15,\n",
        "                                                           zoom_range=0.15)\n",
        "\n",
        "augmented_data_val = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "flow_data_train = augmented_data_train.flow(x_train, y_train)\n",
        "\n",
        "flow_data_val = augmented_data_val.flow(x_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "i8uJ2hRe_jl2",
      "metadata": {
        "id": "i8uJ2hRe_jl2",
        "outputId": "d4ca5efe-f72a-4ed6-cd00-aee904ea7d69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "78/78 [==============================] - 22s 283ms/step - loss: 7.0508 - accuracy: 0.0204 - val_loss: 5.7408 - val_accuracy: 0.0139\n",
            "Epoch 2/400\n",
            "78/78 [==============================] - 22s 283ms/step - loss: 7.1826 - accuracy: 0.0168 - val_loss: 5.8939 - val_accuracy: 0.0104\n",
            "Epoch 3/400\n",
            "78/78 [==============================] - 22s 283ms/step - loss: 7.2539 - accuracy: 0.0164 - val_loss: 9.3347 - val_accuracy: 0.0104\n",
            "Epoch 4/400\n",
            "78/78 [==============================] - 22s 282ms/step - loss: 6.6585 - accuracy: 0.0164 - val_loss: 6.0995 - val_accuracy: 0.0104\n",
            "Epoch 5/400\n",
            "78/78 [==============================] - 22s 283ms/step - loss: 6.0534 - accuracy: 0.0216 - val_loss: 5.6366 - val_accuracy: 0.0208\n",
            "Epoch 6/400\n",
            "78/78 [==============================] - 22s 283ms/step - loss: 5.8584 - accuracy: 0.0228 - val_loss: 5.4566 - val_accuracy: 0.0174\n",
            "Epoch 7/400\n",
            "78/78 [==============================] - 22s 283ms/step - loss: 5.8599 - accuracy: 0.0240 - val_loss: 6.0863 - val_accuracy: 0.0243\n",
            "Epoch 8/400\n",
            "78/78 [==============================] - 22s 282ms/step - loss: 5.5140 - accuracy: 0.0280 - val_loss: 6.7361 - val_accuracy: 0.0382\n",
            "Epoch 9/400\n",
            "78/78 [==============================] - 22s 282ms/step - loss: 5.3498 - accuracy: 0.0325 - val_loss: 5.1146 - val_accuracy: 0.0382\n",
            "Epoch 10/400\n",
            "78/78 [==============================] - 22s 282ms/step - loss: 5.1808 - accuracy: 0.0429 - val_loss: 6.4780 - val_accuracy: 0.0243\n",
            "Epoch 11/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 5.0720 - accuracy: 0.0437 - val_loss: 5.2633 - val_accuracy: 0.0347\n",
            "Epoch 12/400\n",
            "78/78 [==============================] - 22s 282ms/step - loss: 5.0024 - accuracy: 0.0553 - val_loss: 6.0717 - val_accuracy: 0.0278\n",
            "Epoch 13/400\n",
            "78/78 [==============================] - 22s 282ms/step - loss: 4.9997 - accuracy: 0.0453 - val_loss: 6.5648 - val_accuracy: 0.0139\n",
            "Epoch 14/400\n",
            "78/78 [==============================] - 22s 282ms/step - loss: 4.9562 - accuracy: 0.0397 - val_loss: 5.1530 - val_accuracy: 0.0660\n",
            "Epoch 15/400\n",
            "78/78 [==============================] - 22s 283ms/step - loss: 4.8458 - accuracy: 0.0553 - val_loss: 4.7515 - val_accuracy: 0.0764\n",
            "Epoch 16/400\n",
            "78/78 [==============================] - 22s 282ms/step - loss: 4.8505 - accuracy: 0.0501 - val_loss: 4.9290 - val_accuracy: 0.0451\n",
            "Epoch 17/400\n",
            "78/78 [==============================] - 22s 282ms/step - loss: 4.8657 - accuracy: 0.0489 - val_loss: 5.4208 - val_accuracy: 0.0417\n",
            "Epoch 18/400\n",
            "78/78 [==============================] - 22s 282ms/step - loss: 4.8289 - accuracy: 0.0537 - val_loss: 5.7329 - val_accuracy: 0.0347\n",
            "Epoch 19/400\n",
            "78/78 [==============================] - 22s 282ms/step - loss: 4.7506 - accuracy: 0.0609 - val_loss: 4.6083 - val_accuracy: 0.0729\n",
            "Epoch 20/400\n",
            "78/78 [==============================] - 22s 282ms/step - loss: 4.7948 - accuracy: 0.0565 - val_loss: 4.8211 - val_accuracy: 0.0521\n",
            "Epoch 21/400\n",
            "78/78 [==============================] - 22s 282ms/step - loss: 4.8129 - accuracy: 0.0529 - val_loss: 4.8274 - val_accuracy: 0.0417\n",
            "Epoch 22/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.7228 - accuracy: 0.0609 - val_loss: 4.8736 - val_accuracy: 0.0521\n",
            "Epoch 23/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.7009 - accuracy: 0.0605 - val_loss: 4.7415 - val_accuracy: 0.0521\n",
            "Epoch 24/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.7801 - accuracy: 0.0549 - val_loss: 4.9340 - val_accuracy: 0.0382\n",
            "Epoch 25/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.7679 - accuracy: 0.0605 - val_loss: 5.7836 - val_accuracy: 0.0278\n",
            "Epoch 26/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.7310 - accuracy: 0.0601 - val_loss: 4.5672 - val_accuracy: 0.0764\n",
            "Epoch 27/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.6869 - accuracy: 0.0641 - val_loss: 13.3461 - val_accuracy: 0.0278\n",
            "Epoch 28/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.6914 - accuracy: 0.0597 - val_loss: 5.1018 - val_accuracy: 0.0556\n",
            "Epoch 29/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.6761 - accuracy: 0.0677 - val_loss: 5.5318 - val_accuracy: 0.0451\n",
            "Epoch 30/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.7174 - accuracy: 0.0665 - val_loss: 5.0719 - val_accuracy: 0.0486\n",
            "Epoch 31/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.6488 - accuracy: 0.0677 - val_loss: 5.0609 - val_accuracy: 0.0660\n",
            "Epoch 32/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.6804 - accuracy: 0.0597 - val_loss: 6.3292 - val_accuracy: 0.0521\n",
            "Epoch 33/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.6813 - accuracy: 0.0637 - val_loss: 6.6806 - val_accuracy: 0.0417\n",
            "Epoch 34/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.6573 - accuracy: 0.0601 - val_loss: 7.8580 - val_accuracy: 0.0069\n",
            "Epoch 35/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.6431 - accuracy: 0.0689 - val_loss: 4.8613 - val_accuracy: 0.0486\n",
            "Epoch 36/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.6526 - accuracy: 0.0705 - val_loss: 4.6537 - val_accuracy: 0.0729\n",
            "Epoch 37/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.6376 - accuracy: 0.0609 - val_loss: 4.3869 - val_accuracy: 0.1111\n",
            "Epoch 38/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.6187 - accuracy: 0.0697 - val_loss: 5.0800 - val_accuracy: 0.0312\n",
            "Epoch 39/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.6119 - accuracy: 0.0733 - val_loss: 4.6655 - val_accuracy: 0.0660\n",
            "Epoch 40/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.6127 - accuracy: 0.0673 - val_loss: 5.5919 - val_accuracy: 0.0312\n",
            "Epoch 41/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.6084 - accuracy: 0.0729 - val_loss: 4.9707 - val_accuracy: 0.0486\n",
            "Epoch 42/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.5660 - accuracy: 0.0701 - val_loss: 5.6277 - val_accuracy: 0.0174\n",
            "Epoch 43/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.6599 - accuracy: 0.0669 - val_loss: 6.7213 - val_accuracy: 0.0521\n",
            "Epoch 44/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.5804 - accuracy: 0.0705 - val_loss: 4.5703 - val_accuracy: 0.0556\n",
            "Epoch 45/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.5714 - accuracy: 0.0761 - val_loss: 5.2838 - val_accuracy: 0.0521\n",
            "Epoch 46/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.5735 - accuracy: 0.0717 - val_loss: 5.9413 - val_accuracy: 0.0625\n",
            "Epoch 47/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.5569 - accuracy: 0.0845 - val_loss: 7.8727 - val_accuracy: 0.0208\n",
            "Epoch 48/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.6037 - accuracy: 0.0749 - val_loss: 5.1054 - val_accuracy: 0.0729\n",
            "Epoch 49/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.5875 - accuracy: 0.0749 - val_loss: 5.5075 - val_accuracy: 0.0590\n",
            "Epoch 50/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.5708 - accuracy: 0.0745 - val_loss: 4.4356 - val_accuracy: 0.0799\n",
            "Epoch 51/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.5952 - accuracy: 0.0761 - val_loss: 6.1092 - val_accuracy: 0.0382\n",
            "Epoch 52/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.5412 - accuracy: 0.0809 - val_loss: 4.6128 - val_accuracy: 0.0521\n",
            "Epoch 53/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.5167 - accuracy: 0.0857 - val_loss: 5.1759 - val_accuracy: 0.0312\n",
            "Epoch 54/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.5271 - accuracy: 0.0893 - val_loss: 5.6092 - val_accuracy: 0.0556\n",
            "Epoch 55/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.5794 - accuracy: 0.0673 - val_loss: 5.0355 - val_accuracy: 0.0660\n",
            "Epoch 56/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.5085 - accuracy: 0.0761 - val_loss: 4.7169 - val_accuracy: 0.0799\n",
            "Epoch 57/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.4615 - accuracy: 0.0709 - val_loss: 5.0299 - val_accuracy: 0.0625\n",
            "Epoch 58/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.5110 - accuracy: 0.0813 - val_loss: 4.5747 - val_accuracy: 0.1042\n",
            "Epoch 59/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 82.2216 - accuracy: 0.0533 - val_loss: 3514978.5000 - val_accuracy: 0.0035\n",
            "Epoch 60/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 268.0257 - accuracy: 0.0056 - val_loss: 28.0298 - val_accuracy: 0.0104\n",
            "Epoch 61/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 8.1308 - accuracy: 0.0096 - val_loss: 6.4955 - val_accuracy: 0.0174\n",
            "Epoch 62/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 6.5054 - accuracy: 0.0088 - val_loss: 5.8619 - val_accuracy: 0.0104\n",
            "Epoch 63/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 6.1873 - accuracy: 0.0072 - val_loss: 5.5833 - val_accuracy: 0.0035\n",
            "Epoch 64/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 5.9613 - accuracy: 0.0080 - val_loss: 5.5582 - val_accuracy: 0.0104\n",
            "Epoch 65/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 5.8698 - accuracy: 0.0100 - val_loss: 5.3842 - val_accuracy: 0.0208\n",
            "Epoch 66/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 5.7231 - accuracy: 0.0120 - val_loss: 5.4794 - val_accuracy: 0.0139\n",
            "Epoch 67/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 5.7250 - accuracy: 0.0128 - val_loss: 5.3932 - val_accuracy: 0.0104\n",
            "Epoch 68/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 5.5905 - accuracy: 0.0212 - val_loss: 5.3470 - val_accuracy: 0.0139\n",
            "Epoch 69/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 5.7198 - accuracy: 0.0172 - val_loss: 5.6526 - val_accuracy: 0.0312\n",
            "Epoch 70/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 5.6483 - accuracy: 0.0160 - val_loss: 5.2439 - val_accuracy: 0.0347\n",
            "Epoch 71/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 5.4780 - accuracy: 0.0184 - val_loss: 5.7918 - val_accuracy: 0.0139\n",
            "Epoch 72/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 5.3596 - accuracy: 0.0248 - val_loss: 5.1731 - val_accuracy: 0.0347\n",
            "Epoch 73/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 5.2932 - accuracy: 0.0296 - val_loss: 5.2174 - val_accuracy: 0.0243\n",
            "Epoch 74/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 5.4540 - accuracy: 0.0216 - val_loss: 5.8215 - val_accuracy: 0.0208\n",
            "Epoch 75/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 5.3812 - accuracy: 0.0176 - val_loss: 12.5721 - val_accuracy: 0.0312\n",
            "Epoch 76/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 5.2878 - accuracy: 0.0276 - val_loss: 5.1836 - val_accuracy: 0.0243\n",
            "Epoch 77/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 5.1991 - accuracy: 0.0357 - val_loss: 4.9544 - val_accuracy: 0.0451\n",
            "Epoch 78/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 5.1709 - accuracy: 0.0317 - val_loss: 5.0394 - val_accuracy: 0.0486\n",
            "Epoch 79/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 5.1370 - accuracy: 0.0385 - val_loss: 5.1214 - val_accuracy: 0.0625\n",
            "Epoch 80/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 5.0866 - accuracy: 0.0345 - val_loss: 5.2648 - val_accuracy: 0.0451\n",
            "Epoch 81/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 5.3113 - accuracy: 0.0353 - val_loss: 4.8877 - val_accuracy: 0.0347\n",
            "Epoch 82/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 5.0407 - accuracy: 0.0397 - val_loss: 4.9657 - val_accuracy: 0.0312\n",
            "Epoch 83/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 5.0404 - accuracy: 0.0373 - val_loss: 5.1813 - val_accuracy: 0.0417\n",
            "Epoch 84/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 5.0249 - accuracy: 0.0421 - val_loss: 5.3002 - val_accuracy: 0.0278\n",
            "Epoch 85/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 5.1348 - accuracy: 0.0393 - val_loss: 4.8856 - val_accuracy: 0.0764\n",
            "Epoch 86/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 5.1249 - accuracy: 0.0385 - val_loss: 4.9403 - val_accuracy: 0.0347\n",
            "Epoch 87/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 5.0061 - accuracy: 0.0397 - val_loss: 5.2501 - val_accuracy: 0.0243\n",
            "Epoch 88/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.9437 - accuracy: 0.0429 - val_loss: 4.8027 - val_accuracy: 0.0729\n",
            "Epoch 89/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.9211 - accuracy: 0.0441 - val_loss: 4.8493 - val_accuracy: 0.0660\n",
            "Epoch 90/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 5.0294 - accuracy: 0.0441 - val_loss: 4.9734 - val_accuracy: 0.0417\n",
            "Epoch 91/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.9397 - accuracy: 0.0473 - val_loss: 5.0652 - val_accuracy: 0.0556\n",
            "Epoch 92/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 5.0027 - accuracy: 0.0445 - val_loss: 5.0443 - val_accuracy: 0.0312\n",
            "Epoch 93/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.8803 - accuracy: 0.0521 - val_loss: 4.9022 - val_accuracy: 0.0556\n",
            "Epoch 94/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.8406 - accuracy: 0.0525 - val_loss: 4.9448 - val_accuracy: 0.0556\n",
            "Epoch 95/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.9194 - accuracy: 0.0485 - val_loss: 4.8704 - val_accuracy: 0.0347\n",
            "Epoch 96/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.8697 - accuracy: 0.0533 - val_loss: 4.6896 - val_accuracy: 0.0868\n",
            "Epoch 97/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.9202 - accuracy: 0.0469 - val_loss: 4.8862 - val_accuracy: 0.0556\n",
            "Epoch 98/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.7743 - accuracy: 0.0697 - val_loss: 4.9158 - val_accuracy: 0.0590\n",
            "Epoch 99/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.8101 - accuracy: 0.0557 - val_loss: 4.8181 - val_accuracy: 0.0556\n",
            "Epoch 100/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.8236 - accuracy: 0.0521 - val_loss: 4.7353 - val_accuracy: 0.0729\n",
            "Epoch 101/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.7886 - accuracy: 0.0629 - val_loss: 4.8132 - val_accuracy: 0.0729\n",
            "Epoch 102/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.7824 - accuracy: 0.0569 - val_loss: 4.7425 - val_accuracy: 0.0729\n",
            "Epoch 103/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.8056 - accuracy: 0.0505 - val_loss: 4.7132 - val_accuracy: 0.0729\n",
            "Epoch 104/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.7544 - accuracy: 0.0609 - val_loss: 4.8555 - val_accuracy: 0.0417\n",
            "Epoch 105/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.7447 - accuracy: 0.0569 - val_loss: 4.6060 - val_accuracy: 0.1076\n",
            "Epoch 106/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.6918 - accuracy: 0.0637 - val_loss: 4.7046 - val_accuracy: 0.0938\n",
            "Epoch 107/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.6678 - accuracy: 0.0661 - val_loss: 4.5639 - val_accuracy: 0.0868\n",
            "Epoch 108/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.6782 - accuracy: 0.0757 - val_loss: 4.4696 - val_accuracy: 0.0764\n",
            "Epoch 109/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.6673 - accuracy: 0.0693 - val_loss: 5.9560 - val_accuracy: 0.0312\n",
            "Epoch 110/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.6264 - accuracy: 0.0777 - val_loss: 4.9124 - val_accuracy: 0.0590\n",
            "Epoch 111/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.6441 - accuracy: 0.0701 - val_loss: 4.7292 - val_accuracy: 0.0694\n",
            "Epoch 112/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.6503 - accuracy: 0.0725 - val_loss: 4.9325 - val_accuracy: 0.0799\n",
            "Epoch 113/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.6083 - accuracy: 0.0725 - val_loss: 4.8223 - val_accuracy: 0.0486\n",
            "Epoch 114/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.6230 - accuracy: 0.0693 - val_loss: 4.7727 - val_accuracy: 0.0729\n",
            "Epoch 115/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.6411 - accuracy: 0.0713 - val_loss: 4.8461 - val_accuracy: 0.0729\n",
            "Epoch 116/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.5891 - accuracy: 0.0777 - val_loss: 5.0240 - val_accuracy: 0.0590\n",
            "Epoch 117/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.6651 - accuracy: 0.0737 - val_loss: 5.1096 - val_accuracy: 0.0625\n",
            "Epoch 118/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.6062 - accuracy: 0.0845 - val_loss: 5.3459 - val_accuracy: 0.0521\n",
            "Epoch 119/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.5935 - accuracy: 0.0761 - val_loss: 4.4649 - val_accuracy: 0.1042\n",
            "Epoch 120/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.5419 - accuracy: 0.0801 - val_loss: 4.8991 - val_accuracy: 0.0799\n",
            "Epoch 121/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.5127 - accuracy: 0.0865 - val_loss: 4.5041 - val_accuracy: 0.1354\n",
            "Epoch 122/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.5040 - accuracy: 0.0829 - val_loss: 4.3555 - val_accuracy: 0.1007\n",
            "Epoch 123/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.5388 - accuracy: 0.0785 - val_loss: 4.5947 - val_accuracy: 0.0833\n",
            "Epoch 124/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.5037 - accuracy: 0.0829 - val_loss: 4.7017 - val_accuracy: 0.0868\n",
            "Epoch 125/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.5199 - accuracy: 0.0885 - val_loss: 4.7414 - val_accuracy: 0.0868\n",
            "Epoch 126/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.5201 - accuracy: 0.0857 - val_loss: 5.4458 - val_accuracy: 0.0556\n",
            "Epoch 127/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.5038 - accuracy: 0.0821 - val_loss: 4.4809 - val_accuracy: 0.0833\n",
            "Epoch 128/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.5509 - accuracy: 0.0829 - val_loss: 4.6881 - val_accuracy: 0.0903\n",
            "Epoch 129/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.5232 - accuracy: 0.0861 - val_loss: 5.4600 - val_accuracy: 0.0451\n",
            "Epoch 130/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4989 - accuracy: 0.0857 - val_loss: 4.8287 - val_accuracy: 0.0833\n",
            "Epoch 131/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.5397 - accuracy: 0.0809 - val_loss: 4.8051 - val_accuracy: 0.0486\n",
            "Epoch 132/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4681 - accuracy: 0.0845 - val_loss: 4.4090 - val_accuracy: 0.0972\n",
            "Epoch 133/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.4677 - accuracy: 0.0958 - val_loss: 4.6812 - val_accuracy: 0.0694\n",
            "Epoch 134/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4585 - accuracy: 0.0845 - val_loss: 5.0817 - val_accuracy: 0.0486\n",
            "Epoch 135/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4556 - accuracy: 0.0885 - val_loss: 4.3601 - val_accuracy: 0.0694\n",
            "Epoch 136/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4895 - accuracy: 0.0853 - val_loss: 4.5287 - val_accuracy: 0.1076\n",
            "Epoch 137/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4015 - accuracy: 0.0933 - val_loss: 4.6857 - val_accuracy: 0.0972\n",
            "Epoch 138/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4120 - accuracy: 0.0970 - val_loss: 4.6559 - val_accuracy: 0.0903\n",
            "Epoch 139/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4244 - accuracy: 0.0925 - val_loss: 4.6704 - val_accuracy: 0.0729\n",
            "Epoch 140/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.5152 - accuracy: 0.0881 - val_loss: 4.4927 - val_accuracy: 0.0833\n",
            "Epoch 141/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4618 - accuracy: 0.0861 - val_loss: 4.6699 - val_accuracy: 0.0729\n",
            "Epoch 142/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3989 - accuracy: 0.0877 - val_loss: 5.3644 - val_accuracy: 0.0660\n",
            "Epoch 143/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.5096 - accuracy: 0.0925 - val_loss: 4.5661 - val_accuracy: 0.0972\n",
            "Epoch 144/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.4655 - accuracy: 0.0905 - val_loss: 4.6135 - val_accuracy: 0.1285\n",
            "Epoch 145/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4950 - accuracy: 0.0865 - val_loss: 4.6045 - val_accuracy: 0.0903\n",
            "Epoch 146/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4626 - accuracy: 0.0929 - val_loss: 4.4516 - val_accuracy: 0.1007\n",
            "Epoch 147/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4651 - accuracy: 0.0893 - val_loss: 4.7702 - val_accuracy: 0.0938\n",
            "Epoch 148/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4457 - accuracy: 0.0881 - val_loss: 4.6981 - val_accuracy: 0.0833\n",
            "Epoch 149/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4505 - accuracy: 0.0889 - val_loss: 4.4774 - val_accuracy: 0.0938\n",
            "Epoch 150/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4838 - accuracy: 0.0885 - val_loss: 5.3843 - val_accuracy: 0.0451\n",
            "Epoch 151/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4288 - accuracy: 0.0917 - val_loss: 5.0392 - val_accuracy: 0.1007\n",
            "Epoch 152/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3911 - accuracy: 0.0990 - val_loss: 4.3133 - val_accuracy: 0.1076\n",
            "Epoch 153/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4444 - accuracy: 0.0998 - val_loss: 4.4798 - val_accuracy: 0.1007\n",
            "Epoch 154/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4175 - accuracy: 0.0913 - val_loss: 4.6153 - val_accuracy: 0.0764\n",
            "Epoch 155/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.4404 - accuracy: 0.0933 - val_loss: 4.6963 - val_accuracy: 0.0799\n",
            "Epoch 156/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4405 - accuracy: 0.0933 - val_loss: 5.1114 - val_accuracy: 0.0556\n",
            "Epoch 157/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.4659 - accuracy: 0.0877 - val_loss: 5.0166 - val_accuracy: 0.0486\n",
            "Epoch 158/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4366 - accuracy: 0.0805 - val_loss: 4.4095 - val_accuracy: 0.1285\n",
            "Epoch 159/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4562 - accuracy: 0.0909 - val_loss: 5.4315 - val_accuracy: 0.0417\n",
            "Epoch 160/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3851 - accuracy: 0.0917 - val_loss: 5.6120 - val_accuracy: 0.0486\n",
            "Epoch 161/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3475 - accuracy: 0.1110 - val_loss: 4.3913 - val_accuracy: 0.0833\n",
            "Epoch 162/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.4298 - accuracy: 0.0994 - val_loss: 6.0465 - val_accuracy: 0.0382\n",
            "Epoch 163/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4581 - accuracy: 0.1022 - val_loss: 4.6055 - val_accuracy: 0.0764\n",
            "Epoch 164/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4573 - accuracy: 0.0921 - val_loss: 4.6993 - val_accuracy: 0.0833\n",
            "Epoch 165/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4185 - accuracy: 0.0986 - val_loss: 4.2024 - val_accuracy: 0.1250\n",
            "Epoch 166/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.4827 - accuracy: 0.0889 - val_loss: 6.2144 - val_accuracy: 0.0312\n",
            "Epoch 167/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4081 - accuracy: 0.0909 - val_loss: 6.2836 - val_accuracy: 0.0312\n",
            "Epoch 168/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.4458 - accuracy: 0.0901 - val_loss: 4.6231 - val_accuracy: 0.0625\n",
            "Epoch 169/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4177 - accuracy: 0.0958 - val_loss: 4.3788 - val_accuracy: 0.0799\n",
            "Epoch 170/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3608 - accuracy: 0.1022 - val_loss: 4.4906 - val_accuracy: 0.1215\n",
            "Epoch 171/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4241 - accuracy: 0.0946 - val_loss: 4.3479 - val_accuracy: 0.1007\n",
            "Epoch 172/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3898 - accuracy: 0.0978 - val_loss: 4.5217 - val_accuracy: 0.0972\n",
            "Epoch 173/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3613 - accuracy: 0.1018 - val_loss: 4.5886 - val_accuracy: 0.0764\n",
            "Epoch 174/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.4280 - accuracy: 0.0950 - val_loss: 4.7559 - val_accuracy: 0.0694\n",
            "Epoch 175/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3920 - accuracy: 0.0933 - val_loss: 4.9810 - val_accuracy: 0.0590\n",
            "Epoch 176/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4420 - accuracy: 0.0917 - val_loss: 4.4359 - val_accuracy: 0.1042\n",
            "Epoch 177/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4706 - accuracy: 0.0825 - val_loss: 4.7876 - val_accuracy: 0.0660\n",
            "Epoch 178/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.5006 - accuracy: 0.0921 - val_loss: 4.3255 - val_accuracy: 0.1215\n",
            "Epoch 179/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.4527 - accuracy: 0.0845 - val_loss: 5.1330 - val_accuracy: 0.0729\n",
            "Epoch 180/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4057 - accuracy: 0.0978 - val_loss: 4.8948 - val_accuracy: 0.0833\n",
            "Epoch 181/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.4153 - accuracy: 0.1014 - val_loss: 5.5036 - val_accuracy: 0.0556\n",
            "Epoch 182/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.4161 - accuracy: 0.0954 - val_loss: 4.4433 - val_accuracy: 0.1389\n",
            "Epoch 183/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.4388 - accuracy: 0.0946 - val_loss: 5.5544 - val_accuracy: 0.0417\n",
            "Epoch 184/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3879 - accuracy: 0.0958 - val_loss: 4.3766 - val_accuracy: 0.1111\n",
            "Epoch 185/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3916 - accuracy: 0.0925 - val_loss: 4.5520 - val_accuracy: 0.0938\n",
            "Epoch 186/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4479 - accuracy: 0.0897 - val_loss: 5.1340 - val_accuracy: 0.0417\n",
            "Epoch 187/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.3709 - accuracy: 0.1014 - val_loss: 4.2916 - val_accuracy: 0.1111\n",
            "Epoch 188/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4321 - accuracy: 0.0849 - val_loss: 4.8712 - val_accuracy: 0.0625\n",
            "Epoch 189/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.4370 - accuracy: 0.1006 - val_loss: 5.2424 - val_accuracy: 0.0417\n",
            "Epoch 190/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4370 - accuracy: 0.0877 - val_loss: 5.0845 - val_accuracy: 0.0694\n",
            "Epoch 191/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3618 - accuracy: 0.1098 - val_loss: 4.7223 - val_accuracy: 0.0799\n",
            "Epoch 192/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4098 - accuracy: 0.0901 - val_loss: 4.9511 - val_accuracy: 0.0556\n",
            "Epoch 193/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3656 - accuracy: 0.0909 - val_loss: 4.6530 - val_accuracy: 0.0903\n",
            "Epoch 194/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4233 - accuracy: 0.0901 - val_loss: 4.3231 - val_accuracy: 0.1215\n",
            "Epoch 195/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.3113 - accuracy: 0.1042 - val_loss: 4.6137 - val_accuracy: 0.0903\n",
            "Epoch 196/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4013 - accuracy: 0.0897 - val_loss: 4.5660 - val_accuracy: 0.0833\n",
            "Epoch 197/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3949 - accuracy: 0.1014 - val_loss: 4.6094 - val_accuracy: 0.0590\n",
            "Epoch 198/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3284 - accuracy: 0.0970 - val_loss: 4.7534 - val_accuracy: 0.0764\n",
            "Epoch 199/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3848 - accuracy: 0.0925 - val_loss: 4.9296 - val_accuracy: 0.0729\n",
            "Epoch 200/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4380 - accuracy: 0.0946 - val_loss: 4.3726 - val_accuracy: 0.0729\n",
            "Epoch 201/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3548 - accuracy: 0.0990 - val_loss: 5.4015 - val_accuracy: 0.0556\n",
            "Epoch 202/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3938 - accuracy: 0.0901 - val_loss: 4.7452 - val_accuracy: 0.0660\n",
            "Epoch 203/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4772 - accuracy: 0.0801 - val_loss: 4.6276 - val_accuracy: 0.0833\n",
            "Epoch 204/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.3734 - accuracy: 0.0913 - val_loss: 4.6231 - val_accuracy: 0.0868\n",
            "Epoch 205/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4048 - accuracy: 0.0978 - val_loss: 4.8832 - val_accuracy: 0.0590\n",
            "Epoch 206/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4197 - accuracy: 0.0958 - val_loss: 4.4341 - val_accuracy: 0.0556\n",
            "Epoch 207/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3385 - accuracy: 0.0990 - val_loss: 4.5369 - val_accuracy: 0.0799\n",
            "Epoch 208/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4149 - accuracy: 0.0966 - val_loss: 4.5053 - val_accuracy: 0.0868\n",
            "Epoch 209/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.3400 - accuracy: 0.0982 - val_loss: 4.5512 - val_accuracy: 0.0764\n",
            "Epoch 210/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2895 - accuracy: 0.1058 - val_loss: 4.8153 - val_accuracy: 0.0833\n",
            "Epoch 211/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3786 - accuracy: 0.0950 - val_loss: 4.2239 - val_accuracy: 0.0938\n",
            "Epoch 212/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3915 - accuracy: 0.0801 - val_loss: 4.8768 - val_accuracy: 0.0521\n",
            "Epoch 213/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3540 - accuracy: 0.0978 - val_loss: 4.4898 - val_accuracy: 0.0972\n",
            "Epoch 214/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3989 - accuracy: 0.0857 - val_loss: 4.7157 - val_accuracy: 0.0556\n",
            "Epoch 215/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3705 - accuracy: 0.0938 - val_loss: 4.7294 - val_accuracy: 0.0868\n",
            "Epoch 216/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3318 - accuracy: 0.0982 - val_loss: 4.4539 - val_accuracy: 0.0903\n",
            "Epoch 217/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3714 - accuracy: 0.0889 - val_loss: 4.4558 - val_accuracy: 0.1076\n",
            "Epoch 218/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3955 - accuracy: 0.0962 - val_loss: 4.4983 - val_accuracy: 0.1042\n",
            "Epoch 219/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3661 - accuracy: 0.0873 - val_loss: 4.7212 - val_accuracy: 0.0868\n",
            "Epoch 220/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4075 - accuracy: 0.0909 - val_loss: 4.6982 - val_accuracy: 0.0590\n",
            "Epoch 221/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3875 - accuracy: 0.0978 - val_loss: 4.7491 - val_accuracy: 0.0625\n",
            "Epoch 222/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3444 - accuracy: 0.0925 - val_loss: 4.6412 - val_accuracy: 0.0903\n",
            "Epoch 223/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3783 - accuracy: 0.0913 - val_loss: 4.2059 - val_accuracy: 0.1042\n",
            "Epoch 224/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3718 - accuracy: 0.0982 - val_loss: 4.6689 - val_accuracy: 0.0729\n",
            "Epoch 225/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3816 - accuracy: 0.0946 - val_loss: 4.6332 - val_accuracy: 0.0833\n",
            "Epoch 226/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3067 - accuracy: 0.1018 - val_loss: 5.1297 - val_accuracy: 0.0590\n",
            "Epoch 227/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2674 - accuracy: 0.1086 - val_loss: 5.9480 - val_accuracy: 0.0417\n",
            "Epoch 228/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3485 - accuracy: 0.0857 - val_loss: 4.5957 - val_accuracy: 0.1215\n",
            "Epoch 229/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3245 - accuracy: 0.1026 - val_loss: 4.2448 - val_accuracy: 0.1111\n",
            "Epoch 230/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3357 - accuracy: 0.0994 - val_loss: 4.5495 - val_accuracy: 0.0764\n",
            "Epoch 231/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3398 - accuracy: 0.0962 - val_loss: 4.6206 - val_accuracy: 0.0694\n",
            "Epoch 232/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3281 - accuracy: 0.1098 - val_loss: 5.0621 - val_accuracy: 0.0625\n",
            "Epoch 233/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3407 - accuracy: 0.1162 - val_loss: 4.2230 - val_accuracy: 0.1146\n",
            "Epoch 234/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.3117 - accuracy: 0.1046 - val_loss: 4.1853 - val_accuracy: 0.1181\n",
            "Epoch 235/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3342 - accuracy: 0.1054 - val_loss: 4.3062 - val_accuracy: 0.0972\n",
            "Epoch 236/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.2736 - accuracy: 0.1042 - val_loss: 4.2449 - val_accuracy: 0.1042\n",
            "Epoch 237/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3259 - accuracy: 0.0974 - val_loss: 4.4322 - val_accuracy: 0.0903\n",
            "Epoch 238/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2858 - accuracy: 0.1050 - val_loss: 4.4863 - val_accuracy: 0.1076\n",
            "Epoch 239/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2185 - accuracy: 0.1246 - val_loss: 4.5785 - val_accuracy: 0.0938\n",
            "Epoch 240/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3370 - accuracy: 0.0925 - val_loss: 4.6397 - val_accuracy: 0.0764\n",
            "Epoch 241/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3815 - accuracy: 0.0845 - val_loss: 4.6403 - val_accuracy: 0.0868\n",
            "Epoch 242/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3109 - accuracy: 0.1030 - val_loss: 4.3108 - val_accuracy: 0.1007\n",
            "Epoch 243/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3741 - accuracy: 0.0938 - val_loss: 4.8308 - val_accuracy: 0.0625\n",
            "Epoch 244/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2907 - accuracy: 0.1046 - val_loss: 4.7995 - val_accuracy: 0.0764\n",
            "Epoch 245/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3097 - accuracy: 0.0994 - val_loss: 4.2187 - val_accuracy: 0.1181\n",
            "Epoch 246/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2609 - accuracy: 0.1130 - val_loss: 4.5884 - val_accuracy: 0.0868\n",
            "Epoch 247/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2441 - accuracy: 0.1066 - val_loss: 4.5397 - val_accuracy: 0.1007\n",
            "Epoch 248/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2714 - accuracy: 0.1102 - val_loss: 4.4617 - val_accuracy: 0.0868\n",
            "Epoch 249/400\n",
            "78/78 [==============================] - 22s 279ms/step - loss: 4.3237 - accuracy: 0.0998 - val_loss: 4.4976 - val_accuracy: 0.0938\n",
            "Epoch 250/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2241 - accuracy: 0.1130 - val_loss: 4.5198 - val_accuracy: 0.0833\n",
            "Epoch 251/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3065 - accuracy: 0.0958 - val_loss: 4.4202 - val_accuracy: 0.0799\n",
            "Epoch 252/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2804 - accuracy: 0.1090 - val_loss: 4.3239 - val_accuracy: 0.1181\n",
            "Epoch 253/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2442 - accuracy: 0.1062 - val_loss: 4.3941 - val_accuracy: 0.0833\n",
            "Epoch 254/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3539 - accuracy: 0.0958 - val_loss: 4.4865 - val_accuracy: 0.0938\n",
            "Epoch 255/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2611 - accuracy: 0.1058 - val_loss: 4.7278 - val_accuracy: 0.0799\n",
            "Epoch 256/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2284 - accuracy: 0.1130 - val_loss: 4.3122 - val_accuracy: 0.0868\n",
            "Epoch 257/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2643 - accuracy: 0.1074 - val_loss: 4.4566 - val_accuracy: 0.0938\n",
            "Epoch 258/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3002 - accuracy: 0.1058 - val_loss: 5.2319 - val_accuracy: 0.0521\n",
            "Epoch 259/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2893 - accuracy: 0.1110 - val_loss: 4.5896 - val_accuracy: 0.0729\n",
            "Epoch 260/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2795 - accuracy: 0.1158 - val_loss: 4.8743 - val_accuracy: 0.0799\n",
            "Epoch 261/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2181 - accuracy: 0.1110 - val_loss: 4.4802 - val_accuracy: 0.1111\n",
            "Epoch 262/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2898 - accuracy: 0.1018 - val_loss: 4.8110 - val_accuracy: 0.0938\n",
            "Epoch 263/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2536 - accuracy: 0.1082 - val_loss: 4.5068 - val_accuracy: 0.0729\n",
            "Epoch 264/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2623 - accuracy: 0.1110 - val_loss: 5.5414 - val_accuracy: 0.0694\n",
            "Epoch 265/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2645 - accuracy: 0.1110 - val_loss: 4.7805 - val_accuracy: 0.0625\n",
            "Epoch 266/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2120 - accuracy: 0.1070 - val_loss: 5.7579 - val_accuracy: 0.0347\n",
            "Epoch 267/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.2177 - accuracy: 0.1170 - val_loss: 4.7294 - val_accuracy: 0.0694\n",
            "Epoch 268/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2082 - accuracy: 0.1186 - val_loss: 4.5766 - val_accuracy: 0.0729\n",
            "Epoch 269/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2123 - accuracy: 0.1202 - val_loss: 4.2786 - val_accuracy: 0.1250\n",
            "Epoch 270/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2222 - accuracy: 0.1122 - val_loss: 4.9056 - val_accuracy: 0.0660\n",
            "Epoch 271/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2329 - accuracy: 0.1070 - val_loss: 4.3864 - val_accuracy: 0.0799\n",
            "Epoch 272/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1731 - accuracy: 0.1290 - val_loss: 4.3714 - val_accuracy: 0.1146\n",
            "Epoch 273/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2404 - accuracy: 0.1102 - val_loss: 4.3858 - val_accuracy: 0.0903\n",
            "Epoch 274/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1918 - accuracy: 0.1138 - val_loss: 4.6474 - val_accuracy: 0.0938\n",
            "Epoch 275/400\n",
            "78/78 [==============================] - 22s 279ms/step - loss: 4.2179 - accuracy: 0.1110 - val_loss: 4.5721 - val_accuracy: 0.0868\n",
            "Epoch 276/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2469 - accuracy: 0.1038 - val_loss: 5.2788 - val_accuracy: 0.0590\n",
            "Epoch 277/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2539 - accuracy: 0.1078 - val_loss: 4.9321 - val_accuracy: 0.0451\n",
            "Epoch 278/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2377 - accuracy: 0.1122 - val_loss: 4.7036 - val_accuracy: 0.0556\n",
            "Epoch 279/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2314 - accuracy: 0.1230 - val_loss: 4.5636 - val_accuracy: 0.0799\n",
            "Epoch 280/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2241 - accuracy: 0.1110 - val_loss: 4.8748 - val_accuracy: 0.0903\n",
            "Epoch 281/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1929 - accuracy: 0.1038 - val_loss: 4.3063 - val_accuracy: 0.1215\n",
            "Epoch 282/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2253 - accuracy: 0.1042 - val_loss: 4.2507 - val_accuracy: 0.1111\n",
            "Epoch 283/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2014 - accuracy: 0.1178 - val_loss: 4.6075 - val_accuracy: 0.0868\n",
            "Epoch 284/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1932 - accuracy: 0.1146 - val_loss: 4.3307 - val_accuracy: 0.1215\n",
            "Epoch 285/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1925 - accuracy: 0.1150 - val_loss: 4.5888 - val_accuracy: 0.0660\n",
            "Epoch 286/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2408 - accuracy: 0.1142 - val_loss: 4.3792 - val_accuracy: 0.1215\n",
            "Epoch 287/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1147 - accuracy: 0.1282 - val_loss: 4.1785 - val_accuracy: 0.0938\n",
            "Epoch 288/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1581 - accuracy: 0.1178 - val_loss: 4.4314 - val_accuracy: 0.0972\n",
            "Epoch 289/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1888 - accuracy: 0.1238 - val_loss: 5.2440 - val_accuracy: 0.0486\n",
            "Epoch 290/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1917 - accuracy: 0.1150 - val_loss: 4.7700 - val_accuracy: 0.0903\n",
            "Epoch 291/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1498 - accuracy: 0.1218 - val_loss: 4.4320 - val_accuracy: 0.1250\n",
            "Epoch 292/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1809 - accuracy: 0.1178 - val_loss: 4.6358 - val_accuracy: 0.0938\n",
            "Epoch 293/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.1264 - accuracy: 0.1306 - val_loss: 4.4362 - val_accuracy: 0.1076\n",
            "Epoch 294/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2033 - accuracy: 0.1126 - val_loss: 5.6948 - val_accuracy: 0.0903\n",
            "Epoch 295/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1574 - accuracy: 0.1198 - val_loss: 5.3643 - val_accuracy: 0.0694\n",
            "Epoch 296/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1395 - accuracy: 0.1178 - val_loss: 4.4350 - val_accuracy: 0.0833\n",
            "Epoch 297/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1391 - accuracy: 0.1254 - val_loss: 4.3420 - val_accuracy: 0.1076\n",
            "Epoch 298/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1323 - accuracy: 0.1342 - val_loss: 4.3192 - val_accuracy: 0.1146\n",
            "Epoch 299/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.1100 - accuracy: 0.1330 - val_loss: 5.1321 - val_accuracy: 0.0590\n",
            "Epoch 300/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1801 - accuracy: 0.1102 - val_loss: 4.8742 - val_accuracy: 0.0521\n",
            "Epoch 301/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1579 - accuracy: 0.1154 - val_loss: 4.8520 - val_accuracy: 0.0938\n",
            "Epoch 302/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1855 - accuracy: 0.1202 - val_loss: 4.0041 - val_accuracy: 0.1632\n",
            "Epoch 303/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1310 - accuracy: 0.1214 - val_loss: 5.2584 - val_accuracy: 0.0590\n",
            "Epoch 304/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1719 - accuracy: 0.1146 - val_loss: 4.6073 - val_accuracy: 0.0729\n",
            "Epoch 305/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1554 - accuracy: 0.1274 - val_loss: 4.5224 - val_accuracy: 0.0799\n",
            "Epoch 306/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1947 - accuracy: 0.1118 - val_loss: 4.2346 - val_accuracy: 0.1007\n",
            "Epoch 307/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.1169 - accuracy: 0.1266 - val_loss: 4.3882 - val_accuracy: 0.0833\n",
            "Epoch 308/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.0884 - accuracy: 0.1290 - val_loss: 4.6389 - val_accuracy: 0.0660\n",
            "Epoch 309/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1389 - accuracy: 0.1170 - val_loss: 4.4759 - val_accuracy: 0.1007\n",
            "Epoch 310/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 52.3468 - accuracy: 0.1030 - val_loss: 885.7031 - val_accuracy: 0.0104\n",
            "Epoch 311/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 28.6505 - accuracy: 0.0068 - val_loss: 13.8907 - val_accuracy: 0.0069\n",
            "Epoch 312/400\n",
            "78/78 [==============================] - 22s 279ms/step - loss: 5.6411 - accuracy: 0.0176 - val_loss: 5.7594 - val_accuracy: 0.0174\n",
            "Epoch 313/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 5.3709 - accuracy: 0.0200 - val_loss: 5.3954 - val_accuracy: 0.0035\n",
            "Epoch 314/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 5.3783 - accuracy: 0.0264 - val_loss: 5.7158 - val_accuracy: 0.0035\n",
            "Epoch 315/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 5.1860 - accuracy: 0.0329 - val_loss: 5.2018 - val_accuracy: 0.0208\n",
            "Epoch 316/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.9040 - accuracy: 0.0397 - val_loss: 4.8166 - val_accuracy: 0.0590\n",
            "Epoch 317/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.8658 - accuracy: 0.0557 - val_loss: 5.1350 - val_accuracy: 0.0417\n",
            "Epoch 318/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.8398 - accuracy: 0.0545 - val_loss: 5.0379 - val_accuracy: 0.0382\n",
            "Epoch 319/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.7262 - accuracy: 0.0701 - val_loss: 4.5224 - val_accuracy: 0.0799\n",
            "Epoch 320/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.6420 - accuracy: 0.0741 - val_loss: 4.4517 - val_accuracy: 0.0833\n",
            "Epoch 321/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.6725 - accuracy: 0.0733 - val_loss: 4.6207 - val_accuracy: 0.0799\n",
            "Epoch 322/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.5225 - accuracy: 0.0813 - val_loss: 4.5012 - val_accuracy: 0.0799\n",
            "Epoch 323/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.5303 - accuracy: 0.0825 - val_loss: 4.5910 - val_accuracy: 0.0660\n",
            "Epoch 324/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.5180 - accuracy: 0.0825 - val_loss: 4.7870 - val_accuracy: 0.0590\n",
            "Epoch 325/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.6032 - accuracy: 0.0773 - val_loss: 4.4721 - val_accuracy: 0.0729\n",
            "Epoch 326/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.4509 - accuracy: 0.0857 - val_loss: 4.6263 - val_accuracy: 0.0972\n",
            "Epoch 327/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3814 - accuracy: 0.0913 - val_loss: 4.9418 - val_accuracy: 0.0903\n",
            "Epoch 328/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.4939 - accuracy: 0.0841 - val_loss: 4.2534 - val_accuracy: 0.0938\n",
            "Epoch 329/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3327 - accuracy: 0.1102 - val_loss: 4.3939 - val_accuracy: 0.0972\n",
            "Epoch 330/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3390 - accuracy: 0.1030 - val_loss: 4.8416 - val_accuracy: 0.0799\n",
            "Epoch 331/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2699 - accuracy: 0.1118 - val_loss: 4.2536 - val_accuracy: 0.1146\n",
            "Epoch 332/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.3343 - accuracy: 0.1046 - val_loss: 4.4529 - val_accuracy: 0.0938\n",
            "Epoch 333/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3382 - accuracy: 0.1026 - val_loss: 4.5048 - val_accuracy: 0.0972\n",
            "Epoch 334/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.3057 - accuracy: 0.1034 - val_loss: 4.3115 - val_accuracy: 0.1250\n",
            "Epoch 335/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2478 - accuracy: 0.1038 - val_loss: 4.2673 - val_accuracy: 0.1146\n",
            "Epoch 336/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2598 - accuracy: 0.1210 - val_loss: 4.3393 - val_accuracy: 0.1389\n",
            "Epoch 337/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2278 - accuracy: 0.1186 - val_loss: 4.4560 - val_accuracy: 0.1076\n",
            "Epoch 338/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2153 - accuracy: 0.1150 - val_loss: 4.3778 - val_accuracy: 0.1146\n",
            "Epoch 339/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2290 - accuracy: 0.1250 - val_loss: 4.2531 - val_accuracy: 0.0972\n",
            "Epoch 340/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1639 - accuracy: 0.1226 - val_loss: 4.2503 - val_accuracy: 0.1528\n",
            "Epoch 341/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1934 - accuracy: 0.1166 - val_loss: 4.6005 - val_accuracy: 0.0833\n",
            "Epoch 342/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2140 - accuracy: 0.1102 - val_loss: 4.3077 - val_accuracy: 0.1319\n",
            "Epoch 343/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1968 - accuracy: 0.1198 - val_loss: 5.0441 - val_accuracy: 0.0694\n",
            "Epoch 344/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1494 - accuracy: 0.1198 - val_loss: 4.1710 - val_accuracy: 0.1632\n",
            "Epoch 345/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2221 - accuracy: 0.1202 - val_loss: 4.6327 - val_accuracy: 0.1111\n",
            "Epoch 346/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2175 - accuracy: 0.1154 - val_loss: 4.2598 - val_accuracy: 0.1181\n",
            "Epoch 347/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2098 - accuracy: 0.1194 - val_loss: 4.2110 - val_accuracy: 0.1493\n",
            "Epoch 348/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.2037 - accuracy: 0.1122 - val_loss: 4.2468 - val_accuracy: 0.1042\n",
            "Epoch 349/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.0970 - accuracy: 0.1242 - val_loss: 4.4502 - val_accuracy: 0.1354\n",
            "Epoch 350/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1471 - accuracy: 0.1242 - val_loss: 4.1644 - val_accuracy: 0.1389\n",
            "Epoch 351/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1138 - accuracy: 0.1342 - val_loss: 4.4804 - val_accuracy: 0.1250\n",
            "Epoch 352/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1111 - accuracy: 0.1302 - val_loss: 4.7368 - val_accuracy: 0.0938\n",
            "Epoch 353/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.0966 - accuracy: 0.1346 - val_loss: 4.3269 - val_accuracy: 0.1007\n",
            "Epoch 354/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.0523 - accuracy: 0.1322 - val_loss: 4.3846 - val_accuracy: 0.1250\n",
            "Epoch 355/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1122 - accuracy: 0.1334 - val_loss: 4.3631 - val_accuracy: 0.0938\n",
            "Epoch 356/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.0976 - accuracy: 0.1406 - val_loss: 4.5172 - val_accuracy: 0.1181\n",
            "Epoch 357/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1556 - accuracy: 0.1226 - val_loss: 4.3481 - val_accuracy: 0.1250\n",
            "Epoch 358/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.0510 - accuracy: 0.1402 - val_loss: 3.9913 - val_accuracy: 0.1528\n",
            "Epoch 359/400\n",
            "78/78 [==============================] - 22s 281ms/step - loss: 4.1610 - accuracy: 0.1258 - val_loss: 4.4580 - val_accuracy: 0.1007\n",
            "Epoch 360/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1064 - accuracy: 0.1310 - val_loss: 4.1711 - val_accuracy: 0.1562\n",
            "Epoch 361/400\n",
            "78/78 [==============================] - 22s 279ms/step - loss: 4.0596 - accuracy: 0.1402 - val_loss: 4.1435 - val_accuracy: 0.1354\n",
            "Epoch 362/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.0870 - accuracy: 0.1302 - val_loss: 3.8472 - val_accuracy: 0.1424\n",
            "Epoch 363/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1408 - accuracy: 0.1182 - val_loss: 4.2792 - val_accuracy: 0.1181\n",
            "Epoch 364/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1716 - accuracy: 0.1254 - val_loss: 4.2004 - val_accuracy: 0.1007\n",
            "Epoch 365/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.0863 - accuracy: 0.1314 - val_loss: 3.9772 - val_accuracy: 0.1285\n",
            "Epoch 366/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1141 - accuracy: 0.1306 - val_loss: 4.9084 - val_accuracy: 0.0764\n",
            "Epoch 367/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.0566 - accuracy: 0.1314 - val_loss: 4.5927 - val_accuracy: 0.0903\n",
            "Epoch 368/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.0818 - accuracy: 0.1266 - val_loss: 4.9156 - val_accuracy: 0.0868\n",
            "Epoch 369/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.0684 - accuracy: 0.1342 - val_loss: 4.1724 - val_accuracy: 0.1632\n",
            "Epoch 370/400\n",
            "78/78 [==============================] - 22s 279ms/step - loss: 4.0360 - accuracy: 0.1334 - val_loss: 4.6871 - val_accuracy: 0.0903\n",
            "Epoch 371/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.0930 - accuracy: 0.1370 - val_loss: 4.2254 - val_accuracy: 0.1250\n",
            "Epoch 372/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.0569 - accuracy: 0.1382 - val_loss: 3.9033 - val_accuracy: 0.1493\n",
            "Epoch 373/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.0569 - accuracy: 0.1322 - val_loss: 4.0192 - val_accuracy: 0.1285\n",
            "Epoch 374/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.0724 - accuracy: 0.1326 - val_loss: 3.9894 - val_accuracy: 0.1562\n",
            "Epoch 375/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1162 - accuracy: 0.1290 - val_loss: 4.8829 - val_accuracy: 0.0764\n",
            "Epoch 376/400\n",
            "78/78 [==============================] - 22s 279ms/step - loss: 4.0629 - accuracy: 0.1298 - val_loss: 4.5451 - val_accuracy: 0.1042\n",
            "Epoch 377/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.0934 - accuracy: 0.1334 - val_loss: 4.2119 - val_accuracy: 0.1458\n",
            "Epoch 378/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.0792 - accuracy: 0.1322 - val_loss: 4.1145 - val_accuracy: 0.1597\n",
            "Epoch 379/400\n",
            "78/78 [==============================] - 22s 279ms/step - loss: 4.0869 - accuracy: 0.1250 - val_loss: 5.6324 - val_accuracy: 0.0868\n",
            "Epoch 380/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.0559 - accuracy: 0.1286 - val_loss: 4.4700 - val_accuracy: 0.0972\n",
            "Epoch 381/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.0571 - accuracy: 0.1442 - val_loss: 4.1816 - val_accuracy: 0.1701\n",
            "Epoch 382/400\n",
            "78/78 [==============================] - 22s 279ms/step - loss: 4.0735 - accuracy: 0.1374 - val_loss: 4.9720 - val_accuracy: 0.0972\n",
            "Epoch 383/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.0759 - accuracy: 0.1342 - val_loss: 4.1295 - val_accuracy: 0.1458\n",
            "Epoch 384/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.0620 - accuracy: 0.1442 - val_loss: 4.4326 - val_accuracy: 0.0903\n",
            "Epoch 385/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.0989 - accuracy: 0.1294 - val_loss: 4.2683 - val_accuracy: 0.0972\n",
            "Epoch 386/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.0509 - accuracy: 0.1410 - val_loss: 4.2733 - val_accuracy: 0.1146\n",
            "Epoch 387/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.0732 - accuracy: 0.1338 - val_loss: 4.6112 - val_accuracy: 0.1042\n",
            "Epoch 388/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1328 - accuracy: 0.1174 - val_loss: 4.1654 - val_accuracy: 0.1493\n",
            "Epoch 389/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.0775 - accuracy: 0.1374 - val_loss: 4.6980 - val_accuracy: 0.0972\n",
            "Epoch 390/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1040 - accuracy: 0.1314 - val_loss: 4.1869 - val_accuracy: 0.1146\n",
            "Epoch 391/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.0611 - accuracy: 0.1346 - val_loss: 4.1256 - val_accuracy: 0.1285\n",
            "Epoch 392/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1053 - accuracy: 0.1302 - val_loss: 4.2606 - val_accuracy: 0.0938\n",
            "Epoch 393/400\n",
            "78/78 [==============================] - 22s 279ms/step - loss: 4.0075 - accuracy: 0.1466 - val_loss: 4.5618 - val_accuracy: 0.1111\n",
            "Epoch 394/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.0589 - accuracy: 0.1378 - val_loss: 4.2694 - val_accuracy: 0.1319\n",
            "Epoch 395/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1732 - accuracy: 0.1186 - val_loss: 4.6250 - val_accuracy: 0.0799\n",
            "Epoch 396/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1215 - accuracy: 0.1234 - val_loss: 4.1597 - val_accuracy: 0.1389\n",
            "Epoch 397/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1283 - accuracy: 0.1190 - val_loss: 4.4937 - val_accuracy: 0.0764\n",
            "Epoch 398/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.0431 - accuracy: 0.1326 - val_loss: 4.4746 - val_accuracy: 0.1181\n",
            "Epoch 399/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.1253 - accuracy: 0.1282 - val_loss: 3.8994 - val_accuracy: 0.1736\n",
            "Epoch 400/400\n",
            "78/78 [==============================] - 22s 280ms/step - loss: 4.0446 - accuracy: 0.1286 - val_loss: 4.0802 - val_accuracy: 0.1319\n"
          ]
        }
      ],
      "source": [
        "tic = time.time()\n",
        "\n",
        "#callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
        "\n",
        "history_imagenet = model_imagenet.fit(flow_data_train, validation_data=flow_data_val, batch_size=1024, \n",
        "                                        steps_per_epoch=flow_data_train.n // 1024, validation_steps=flow_data_val.n // 1024, epochs = 400)\n",
        "\n",
        "toc = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1t9mUtlE_jl2",
      "metadata": {
        "id": "1t9mUtlE_jl2",
        "outputId": "1047602a-6694-45e7-f79e-c32830c6f01c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Time to train ImageNet:  146.39513926506044 mins\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n Time to train ImageNet: \", (toc - tic)/60, \"mins\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UFZMoRBQ_jl2",
      "metadata": {
        "id": "UFZMoRBQ_jl2",
        "outputId": "14d81b83-f4df-4cca-f6e1-836a4b4cc1d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Loss vs Epochs')"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize=(15, 5))\n",
        "\n",
        "axes[0].plot(history_imagenet.history['accuracy'])\n",
        "axes[0].set_xlabel('Epochs')\n",
        "axes[0].set_ylabel('Accuracy')\n",
        "axes[0].set_title(\"Accuracy vs Epochs\")\n",
        "\n",
        "axes[1].plot(history_imagenet.history['loss'])\n",
        "axes[1].set_xlabel('Epochs')\n",
        "axes[1].set_ylabel('Loss')\n",
        "axes[1].set_title(\"Loss vs Epochs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Q6786eRE_jl2",
      "metadata": {
        "id": "Q6786eRE_jl2",
        "outputId": "7d9b0358-d0ca-47a8-e3a3-3d10cd83d67f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        }
      ],
      "source": [
        "model_imagenet.save('model_imagenet.h5')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "tiny_imagenet (1).ipynb",
      "provenance": []
    },
    "environment": {
      "kernel": "python3",
      "name": "tf2-gpu.2-7.m87",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-7:m87"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
